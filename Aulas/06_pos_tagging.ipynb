{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging (análise morfológica)\n",
    "\n",
    "Part-of-speech tagging é a tarefa de identificar as classes morfológicas das palavras de uma frase. Nesta aula, usaremos o conceito de n-gramas para nos ajudar a identificar classes morfológicas automaticamente.\n",
    "\n",
    "## Exercício 1\n",
    "**Objetivo: lembrar-se do que é uma classe morfológica**\n",
    "\n",
    "Nas frases abaixo, identifique os *substantivos*, os *verbos*, os *adjetivos* e os *advérbios*:\n",
    "\n",
    "1. Hoje eu acordei serenamente e vi que era um dia lindo e calmo.\n",
    "1. A mutação dos fungos é capaz de controlar a mente das pessoas!\n",
    "1. Todo dia, o Sol da manhã vem e nos desafia!\n",
    "1. Não adianta tentar fazer um sistema automático que faz alguma coisa que não entendemos o resultado!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "**Objetivo: representar classes morfológicas no computador**\n",
    "\n",
    "Quando falamos de *part-of-speech tagging*, queremos associar cada token de um texto a uma etiqueta que representa sua classe morfológica. A tarefa de rotular tokens pode ser realizada por pacotes prontos, por exemplo pelo `DefaultTagger` do `nltk`, que atribui o mesmo rótulo a qualquer token que seja recebido.\n",
    "\n",
    "No exemplo abaixo, usamos o rótulo `N` (*noun*, ou \"substantivo\").\n",
    "\n",
    "1. Como um par token+rótulo é representado?\n",
    "1. Na frase usada como exemplo, qual é a acurácia do rotulador?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uma', 'N'),\n",
       " ('frase', 'N'),\n",
       " ('qualquer', 'N'),\n",
       " (':', 'N'),\n",
       " ('ótimo', 'N'),\n",
       " ('para', 'N'),\n",
       " ('dar', 'N'),\n",
       " ('aula', 'N'),\n",
       " ('!', 'N')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger('N')\n",
    "tokens = re.findall(r'\\w+|[.,!?:]+', \"uma frase qualquer: ótimo para dar aula!\")\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "**Objetivo: entender como funciona um banco de dados de tags**\n",
    "\n",
    "Uma estratégia menos \"inocente\" que atribuir a mesma tag a todos os tokens é criar um grande banco de dados nos quais relacionamos palavras a tags. Por exemplo, a palavra \"Brasil\" é um substantivo, a palavra \"andar\" é um verbo, e assim por diante. Para construir esse dicionário, podemos usar um grande conjunto de frases rotuladas.\n",
    "\n",
    "O corpus [macmorpho](http://www.nilc.icmc.usp.br/macmorpho/) tem uma série de anotações de *part-of-speech* na língua portuguesa.\n",
    "\n",
    "1. Nos códigos abaixo, verifique como as tags são associadas a palavras no corpus macmorpho.\n",
    "1. Como a instrução `re.findall` foi usada para extrair as tuplas de tokens/tags nesse corpus? A expressão regular usada poderia ser melhorada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jersei_N atinge_V média_N de_PREP Cr$_CUR 1,4_NUM milhão_N na_PREP+ART venda_N da_PREP+ART Pinhal_NPROP em_PREP São_NPROP Paulo_NPROP ._PU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/macmorpho-train.txt', 'r', encoding='utf-8') as f:\n",
    "    print(f.readline())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ('de', 'PREP'), ('$', 'CUR'), ('4', 'NUM'), ('milhão', 'N'), ('na', 'PREP+ART'), ('venda', 'N'), ('da', 'PREP+ART'), ('Pinhal', 'NPROP'), ('em', 'PREP'), ('São', 'NPROP'), ('Paulo', 'NPROP'), (' .', 'PU')]\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/macmorpho-train.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens = [re.findall(r'(\\w+|[\\W]+)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "print(tokens[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4\n",
    "**Objetivo: avaliar um pos-tagger**\n",
    "\n",
    "O método `accuracy` permite avaliar um tagger com base em um gabarito. Por exemplo, podemos usar a base de teste do *macmorpho* para fazer essa avaliação.\n",
    "\n",
    "1. Com base no código abaixo, qual é a acurácia do tagger se simplesmente assumirmos que todas as palavras são substantivos?\n",
    "1. E se a tag padrão for `V` (verbo), qual seria a acurácia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2048628435917992"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./datasets/macmorpho-test.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens_test = [re.findall(r'(\\w+|[\\W]+)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "default_tagger.accuracy(tokens_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "**Objetivo: treinar e avaliar um pos-tagger**\n",
    "\n",
    "Uma maneira de encontrar quais palavras devem receber determinadas tags é treinar um dicionário em um grande banco de dados e simplesmente atribuir a cada palavra o rótulo que é mais comum a essa palavra, ou seja, usar a probabilidade da tag $t$ dado que sabemos a palavra $w$:\n",
    "\n",
    "$$\n",
    "P(t | w)\n",
    "$$\n",
    "\n",
    "Isso pode ser implementado no nltk usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "unigram_tagger = UnigramTagger(tokens, backoff=default_tagger)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Diferente do `sklearn`, fazemos o treinamento do `UnigramTagger` já quando ele é instanciado. Qual é o parâmetro que indica o banco de dados de treinamento?\n",
    "1. O que significa `backoff`, e por que ele é importante?\n",
    "1. Qual é a acurácia do `UnigramTagger` com backoff no `macmorpho-test`?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "**Objetivo: treinar e avaliar um pos-tagger baseado em bigramas**\n",
    "\n",
    "Algumas palavras, como \"Brasil\", claramente pertencem a uma classe morfológica única. Outras, como \"andar\", podem assumir classes gramaticais diferentes dependendo do contexto (\"eu moro no terceiro andar\" / \"vou andar até ali\"). Para resolver essa questão, podemos usar *n-gramas* ao invés de palavras para encontrar a tag, isto é:\n",
    "\n",
    "$$\n",
    "P(t_n | w_n, w_{n-1}, ..., w_{n-N-1})\n",
    "$$\n",
    "\n",
    "Podemos implementar um tagger baseado em bi-gramas usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NgramTagger\n",
    "bigram_tagger = NgramTagger(n=2, train=tokens, backoff=unigram_tagger)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste código:\n",
    "\n",
    "1. Onde especificamos que o tagger deve conter bigramas?\n",
    "1. Qual é a importância do backoff nesse caso?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7\n",
    "**Objetivo: implementar e testar taggers com n-gramas**\n",
    "\n",
    "Tomando por base os códigos anteriores, implemente e avalie um pos-tagger com trigramas e depois com tetragramas.\n",
    "\n",
    "1. A acurácia aumenta significativamente quando aumentamos o contexto?\n",
    "1. O que acontece com a acurácia se removermos o backoff?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8\n",
    "**Objetivo: testar o tagger em situações reais**\n",
    "\n",
    "Verifique como seu tagger se comporta quando tenta rotular:\n",
    "\n",
    "1. Uma frase que poderia ser usada normalmente na língua escrita\n",
    "1. Uma frase com neologismos usados na Internet como \"vc\", \"rsrsrs\", etc.\n",
    "1. Emoticons como \":)\" ou \":-)\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 9\n",
    "**Objetivo: salvar o tagger e carregar em outro contexto**\n",
    "\n",
    "Usando `joblib`, podemos salvar nosso tagger para evitar ter que carregar toda a base de dados em outro contexto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('esta', 'PROADJ'),\n",
       " ('alsdkfjasdljf', 'N'),\n",
       " ('uma', 'ART'),\n",
       " ('frase,', 'N'),\n",
       " (':-)', 'N'),\n",
       " ('cheia', 'ADJ'),\n",
       " ('de', 'PREP'),\n",
       " ('coisas', 'N'),\n",
       " ('novas', 'ADJ')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(unigram_tagger, 'tagger.joblib')\n",
    "tagger = joblib.load('tagger.joblib')\n",
    "tagger.tag(\"esta alsdkfjasdljf uma frase, :-) cheia de coisas novas\".split())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o `joblib`, salve o melhor tagger que você encontrou nesta aula. Envie o arquivo `.joblib` para um colega e, ao receber um tagger de volta, teste-o."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111468663979414\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk import NgramTagger\n",
    "import joblib\n",
    "\n",
    "with open('./datasets/macmorpho-train.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens = [re.findall(r'(\\w+|[\\W]+)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "\n",
    "default_tagger = DefaultTagger('N')\n",
    "unigram_tagger = UnigramTagger(tokens, backoff=default_tagger)\n",
    "bigram_tagger = NgramTagger(n=2, train=tokens, backoff=unigram_tagger)\n",
    "trigram_tagger = NgramTagger(n=3, train=tokens, backoff=bigram_tagger)\n",
    "\n",
    "with open('./datasets/macmorpho-test.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens_test = [re.findall(r'(\\w+|[\\W]+)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "    \n",
    "print(trigram_tagger.accuracy(tokens_test))\n",
    "\n",
    "joblib.dump(trigram_tagger, 'tagger.joblib')\n",
    "tagger = joblib.load('tagger.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28a48ae6583e1b94abe98b0fc0a2fe606019d17909ce475d8d225fed8710924f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
