{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF e busca por conteúdo\n",
    "\n",
    "Nesta atividade, vamos lidar com a seguinte situação: temos um grande banco de dados com textos, e queremos encontrar qual texto é mais relevante para uma consulta. Esse problema aparece em buscadores como Google, e também em sistemas locais como ElasticSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Title  \\\n",
      "10316               American Ninja   \n",
      "31929               Kshana Kshanam   \n",
      "8832        One Is a Lonely Number   \n",
      "5750   Susie the Little Blue Coupe   \n",
      "5698            One Minute to Zero   \n",
      "\n",
      "                                                    Plot  \n",
      "10316  Private Joe Armstrong (Michael Dudikoff) is co...  \n",
      "31929  The film is the story of a middle class girl (...  \n",
      "8832   The story follows Aimee Brower (Van Devere), w...  \n",
      "5750   Susie is a small blue coupe on display in a de...  \n",
      "5698   Just prior to the North Korean invasion of Sou...   1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATASET = 'datasets/wikipedia_movies.zip'\n",
    "df = pd.read_csv(DATASET).sample(1000)\n",
    "df = df[['Title', 'Plot']]\n",
    "print(df.head(), len(df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "**Objetivo: lembrar-se do que é TF e o que é DF**\n",
    "\n",
    "Identifique o Term Frequency e o Document Frequency nas asserções abaixo:\n",
    "\n",
    "1. Quanto maior o ___, mais comum é a palavra entre os documentos de uma coleção\n",
    "1. Quanto maior o ___, mais vezes a palavra é mencionada num documento específico\n",
    "1. $P(w | \\text{documento})$\n",
    "1. $P(w | \\text{coleção})$\n",
    "1. Ajuda a identificar a coleção da qual um documento faz parte\n",
    "1. Ajuda a identificar um documento dentro de uma coleção"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "**Objetivo: refletir sobre o uso de TF-IDF**\n",
    "\n",
    "A medida TFIDF diz o quão relevante um documento é dentro de uma coleção e em relação a uma palavra específica. Ela é calculada para um par palavra-documento como:\n",
    "\n",
    "$\\text{TFIDF = TF / DF}$\n",
    "\n",
    "Quando um documento tem um TFIDF alto em relação a uma palavra, isso significa que:\n",
    "\n",
    "1. A palavra tende a ser (comum / incomum)\n",
    "1. O documento menciona a palavras (muitas / poucas) vezes\n",
    "\n",
    "Portanto, qual seria uma maneira de escrever um documento que tem intencionalmente um TFIDF alto para uma palavra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "**Objetivo: calcular TFIDF para documentos usando sklearn**\n",
    "\n",
    "TFIDF pode ser entendido como um processo de vetorização, semelhante a usar o CountVectorizer. Abaixo, há um código que mostra um exemplo dessa vetorização usando sklearn. \n",
    "\n",
    "1. Escolhendo um filme aleatório da coleção que carregamos, identifique o TFIDF das palavras \"zombie\", \"fungus\" e \"survival\".\n",
    "1. Identifique o filme que tem o maior TFIDF para a palavra \"zombie\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(df['Plot'])\n",
    "\n",
    "j = vectorizer.vocabulary_['test']\n",
    "print(tfidf[2,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4\n",
    "**Objetivo: implementar uma busca por vários termos simultaneamente**\n",
    "\n",
    "Uma possível maneira de implementar uma busca por vários termos é somar o TFIDF de todas as palavras da query para cada documento da coleção, e então retornar o documento que tem a maior soma. Por exemplo, numa busca por \"zombie fungus survival\" deveríamos somar, para cada documento, o TFIDF de \"zombie\", de \"fungus\" e de \"survival\" e então ordenar o resultado.\n",
    "\n",
    "1. Escreva código que implemente uma busca na base de dados de filmes à partir de uma query específica.\n",
    "1. Qual é a complexidade ($O(...)$) da sua busca?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"zombie fungus survival\"\n",
    "\n",
    "# Implemente sua solução aqui\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "**Objetivo: implementar um índice invertido**\n",
    "\n",
    "Você provavelmente reparou (talvez não tenha reparado, e é tudo bem) que, para fazer a busca, até agora, teve que varrer todos os documentos da sua coleção. Isso provavelmente levaria algum tempo, especialmente quando a coleção começa a aumentar. Para evitar ter que varrer todos os documentos da coleção, podemos implementar uma técnica chamada *índice invertido*. A ideia do índice invertido é usar um dicionário cujas chaves são as palavras do vocabulário e cujo conteúdo é uma lista de documentos que contém essa palavra, possivelmente acompanhados do TFIDF correspondente. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documento_1': 0.5, 'documento_2': 0.7}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice = { 'palavra_1' : {'documento_1': 0.5, 'documento_2': 0.1}, \n",
    "          'palavra_2' : {'documento_2': 0.6}   }\n",
    "\n",
    "def buscar(palavras, indice):\n",
    "    assert type(palavras)==list\n",
    "    resultado = dict()\n",
    "    for p in palavras:\n",
    "        if p in indice.keys():\n",
    "            for documento in indice[p].keys():\n",
    "                if documento not in resultado.keys():\n",
    "                    resultado[documento] = indice[p][documento]\n",
    "                else:\n",
    "                    resultado[documento] += indice[p][documento]\n",
    "    return resultado\n",
    "\n",
    "buscar(['palavra_1', 'palavra_2'], indice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adicione uma nova palavra ao índice e escolha seu TFIDF. Realize uma nova busca e verifique o resultado.\n",
    "1. Escreva uma função que ordena o resultado e retorna apenas `N` documentos mais relevantes para sua busca.\n",
    "1. Incremente sua biblioteca de forma que ela passe a receber uma string como entrada (representando a query) e retorne os `N` documentos mais relevantes (`N` pode ser definido arbitrariamente)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "**Objetivo: implementar um buscador de filmes**\n",
    "\n",
    "Implemente uma função que recebe como entrada uma query e retorna os títulos e enredos dos 5 filmes mais relevantes para aquela query. Se precisar, use mais parâmetros ou variáveis globais. Teste a sua função e veja se você concorda com os resultados, incluindo se você consegue encontrar seus filmes favoritos e se consegue alguma recomendação relevante a um filme novo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_movies(query : str):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7\n",
    "**Objetivo: identificar palavras-chave usando TFIDF**\n",
    "\n",
    "Uma outra aplicação de TFIDF é encontrar palavras-chave, isto é, palavras que diferenciam um documento do restante dos documentos de sua coleção.\n",
    "\n",
    "Incremente seu buscador de forma que, além do título e enredo, ele também escolha as algumas palavras (escolha quantas!) mais relevantes de cada documento e as imprima como keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8\n",
    "**Objetivo: encontrar documentos semelhantes usando TFIDF**\n",
    "\n",
    "Uma maneira de encontrar documentos semelhantes em uma coleção de textos é assumir que o texto do documento é uma query, e então realizar a busca normalmente. O problema disso é que provavelmente teríamos textos muito longos e a query ficaria muito carregada. Para solucionar isso, poderíamos usar apenas as palavras mais relevantes de um documento como query. Implemente uma função que recebe o índice (ou outro identificador único) de um documento de nosso banco de dados e então encontra 5 documentos semelhantes a ele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
