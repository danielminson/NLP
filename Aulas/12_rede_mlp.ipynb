{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "**Objetivo: retomar o classificador logístico**\n",
    "\n",
    "Até o momento, usamos a regressão logística como método para classificação.\n",
    "\n",
    "Com suas palavras, discuta: o que cada etapa da pipeline de classificação abaixo faz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/IMDB Dataset.csv').sample(1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Pipeline([\n",
    "                        ('meu_vetorizador', CountVectorizer(stop_words='english', binary=True, max_features=500)),\n",
    "                        ('meu_classificador', LogisticRegression(penalty=None, solver='saga', max_iter=10000))\n",
    "                        ])\n",
    "classificador.fit(X_train,y_train)\n",
    "y_pred = classificador.predict(X_test)\n",
    "acc = accuracy_score(y_pred,y_test)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "*Objetivo: implementar o regressor logístico usando Keras*\n",
    "\n",
    "O regressor logístico, para diferenciar entre duas classes, faz o seguinte processo:\n",
    "\n",
    "1. Uma das classes é associada à saída 1, e a outra é associada à saída -1\n",
    "1. O classificador recebe como entrada um vetor-coluna $x$\n",
    "1. A entrada é multiplicada por um vetor de pesos e depois somada a um *bias*, gerando $y_1 = x^T w + b$\n",
    "1. A função $\\tanh()$ é aplicada a $y_1$, gerando a saída $\\hat{y} = \\tanh(y_1)$\n",
    "\n",
    "Quando estamos *treinando* o regressor logístico (na chamada `.fit()`), ajustamos os pesos $w$ para que o erro quadrático médio seja reduzido em um conjunto de treinamento.\n",
    "\n",
    "Vamos implementar essa mesma sequência usando Keras, isto é, vamos executar uma pequena rede neural para fazer essa mesma tarefa.\n",
    "\n",
    "No código abaixo, identifique as partes correspondentes a cada uma dessas etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processar_saidas(y):\n",
    "    y_out = np.zeros_like(y)\n",
    "    y_out[ y=='negative' ] = -1.0\n",
    "    y_out[ y=='positive' ] = 1.0\n",
    "    y_out = y_out.reshape( (-1, 1))\n",
    "    return y_out.astype(float)\n",
    "\n",
    "y_train_ = pre_processar_saidas(y_train)\n",
    "y_test_ = pre_processar_saidas(y_test)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=True, max_features=500)\n",
    "X_train_ = vectorizer.fit_transform(X_train).todense().astype(float)\n",
    "X_test_ = vectorizer.transform(X_test).todense().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(vocab_size=500):\n",
    "    input_layer = Input(shape=(vocab_size,))\n",
    "    x = input_layer\n",
    "    x = Dense(1, name='classificador')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "clf = base_model()\n",
    "clf.compile(loss='mean_squared_error', metrics=['accuracy'])\n",
    "clf.fit(X_train_, y_train_, epochs=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = clf.evaluate(X_test_, y_test_)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_)\n",
    "#print(y_pred.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3\n",
    "**Objetivo: visualizar parâmetros da rede neural**\n",
    "\n",
    "À partir do código abaixo, responda:\n",
    "\n",
    "1. Quantos parâmetros a rede neural tem? O que eles representam?\n",
    "1. Como podemos acessar os pesos de uma camada da rede?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.get_layer('classificador').weights[0].shape)\n",
    "print(clf.get_layer('classificador').weights[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 4\n",
    "*Objetivo: monitorar o erro de treinamento e de validação em um treinamento de rede*\n",
    "\n",
    "Usualmente, o que vemos em redes neurais é que o erro em relação ao conjunto de treino cai, ao passo que o erro em relação ao conjunto de teste tende a subir. Por isso, em geral separamos uma parte do conjunto de treino a chamamos de \"validação\". Daí, monitoramos o erro no conjunto de validação.\n",
    "\n",
    "O pacotre `keras` nos permite monitorar ambos os erros (treino e validação) através do objeto `history`, que é retornado pelo método `.fit()`.\n",
    "\n",
    "1. O que significa cada um dos painéis gerados pelo código abaixo? Adicione o `plt.xlabel` e `plt.ylabel` para completar os paineis.\n",
    "1. Aumente o número de épocas de treinamento para 100. Como os erros monitorados se comportam?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = base_model()\n",
    "clf.compile(loss='mean_squared_error', metrics=['accuracy'])\n",
    "history = clf.fit(X_train_, y_train_, epochs=5, verbose=1, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,1))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(14,1))\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 5\n",
    "*Objetivo: usar a representação one-hot para as saídas da rede*\n",
    "\n",
    "Até este momento, estamos minimizando o EQM entre a saída predita e a saída \"correta\" de nossa base de dados. O EQM parece estar ligado ao erro de predição, mas só até um certo limite. Vamos agora testar outra ideia.\n",
    "\n",
    "As saídas da nossa rede serão tantas quantas as classes de nosso conjunto. Cada uma das saídas representará a probabilidade da entrada pertencer à classe correspondente, isto é, a saída $n$ significa:\n",
    "\n",
    "$$\n",
    "P(C_n | x)\n",
    "$$\n",
    "\n",
    "Para isso, vamos fazer as seguintes alterações na nossa rede:\n",
    "\n",
    "1. Teremos duas saída, e não mais uma única saída,\n",
    "1. A ativação que utilizaremos será a função `softmax`, que essencialmente força a saída a ter soma 1 ao longo de todas as probabilidades preditas,\n",
    "1. A função de *loss* será a entropia cruzada categórica, que significa que estamos minimizando a probabilidade de erro (e não mais o EQM)\n",
    "\n",
    "Como consequência, precisamos pré-processar nossos rótulos de forma que eles fiquem numa representação one-hot. Keras não nos dá um objeto para lidar com isso, mas sklearn sim:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_train_ = ohe.fit_transform(y_train.to_numpy().reshape((-1,1))).todense()\n",
    "y_test_ = ohe.transform(y_test.to_numpy().reshape((-1,1))).todense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo realiza o treinamento da rede usando a função softmax e a categorical cross-entropy como medida de erro.\n",
    "\n",
    "1. Verifique quantos parâmetros existem na nova rede. O que esses parâmetros significam?\n",
    "1. Adicione código para monitorar o histórico do loss e do accuracy no conjunto de validação, e treine a rede por 50 épocas.\n",
    "1. Após, use o método `.evaluate` para avaliar a rede num conjunto de teste.\n",
    "1. Compare o desempenho deste modelo com o do regressor logístico que foi feito no começo da aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_model(vocab_size=500):\n",
    "    input_layer = Input(shape=(vocab_size,))\n",
    "    x = input_layer\n",
    "    x = Dense(2, name='classificador')(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "clf = softmax_model()\n",
    "print(clf.summary())\n",
    "clf.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = clf.fit(X_train_, y_train_, epochs=5, verbose=1) # validation_split=0.1\n",
    "# clf.evaluate(X_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 6\n",
    "**Objetivo: investigar e interpretar os pesos da rede neural**\n",
    "\n",
    "A camada densa da rede neural recebe como entrada um vetor-coluna $x$, aplica um vetor-coluna de pesos $w$ e depois soma um bias $b$, retornando $x^T w + b$.\n",
    "\n",
    "Em nossa rede neural, o vetor de pesos tem 2 colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.get_layer('classificador').weights[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Por que esse vetor de pesos tem duas colunas?\n",
    "1. Qual é o significado de um peso que está na linha $i$ e na coluna $j$?\n",
    "1. Use o código abaixo para identificar o que a rede, na configuração atual, está \"olhando\" para realizar a classificação. Quais palavras mais tipicamente aparecem em reviews \"positivos\"? Quais palavras mais tipicamente aparecem em reviews \"negativos\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "weights = clf.get_layer('classificador').weights[0].numpy()\n",
    "CLASSE = 0\n",
    "for n in tqdm(range(len(vectorizer.vocabulary_))):\n",
    "    tuplas = [ (weights[vectorizer.vocabulary_[i],CLASSE], i) for i in vectorizer.vocabulary_.keys() ]\n",
    "    tuplas_ordenadas = sorted(tuplas, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "    palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "    contagens = [ t[0] for t in tuplas_ordenadas ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_palavras = 20\n",
    "\n",
    "plt.figure(figsize=(14,1))\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "plt.title(\"Peso das palavras\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 7\n",
    "*Objetivo: fazer um classificador de spam usando rede neural*\n",
    "\n",
    "Usando as estratégias que vimos até o momento, faça um classificador de spam para o spam/ham dataset, mostre suas curvas de aprendizado (treino e validação) e avalie o accuracy do resultado final em um conjunto de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
